I"¡%<p>While I was attempting to rederive some results from a classic 1D transport paper, I got stuck trying to solve for the Greenâ€™s function of the system. The main problem wasnâ€™t a horrendous integral or lack of convergence, but that in the system I was considering there was <em>no translational invariance</em>. The whole usual method of Fourier transforming our Greenâ€™s function into a diagonal basis, inverting it and transforming back could not be used. Our lack of translational invariance means that the Fourier transform no longer neatly decouples our problem into a diagonal basis.</p>

<p>To be clearer, the usual procedure is to start with our generic Greenâ€™s function, \(G(x,x')\), which if we have translational invariance will be a function of the difference of \(x\) and \(x'\) alone, \(G(x-x')\). This reduction of the number of parameters needed means that the Fourier transform only requires one \(k\) to get our answer, \(\tilde{G}(k)\), into a form that we can easily invert. Without translational invariance our Greenâ€™s function will depend on \(k\) and \(k'\) in general.</p>

<p>It isnâ€™t often that we lack translational invariance in physics due to the fact that it is what makes many calculations possible, however there is a neat way to solve the issue in certain cases (otherwise I wouldnâ€™t be writing this at all!). Content here has been lifted from my research into Maslov and Stoneâ€™s 95 paper, full notes of which may appear at some point.</p>

<p>This short explanation will focus on solving the issue when we are focused on finding the Greenâ€™s function to describe the system. Another entry will show a different way in which we can tackle another problem that directly deals with the operators themselves.</p>

<h2 id="greens-function-method">Greenâ€™s Function method</h2>

<p>So simply quoting what the mathematical problem is without much context</p>

\[\begin{equation}
    \Bigg[-\partial_x \frac{v(x)}{K(x)} \partial_x + \frac{\omega^2}{v(x)K(x)} \Bigg] G_{\omega}(x,x') = \delta(x-x')
\end{equation}\]

<p>where the parameters \(v(x), K(x)\) are constant when \(x&lt;0, x&gt;L\) and have a different constant value when \(0 \le x \le L\). We will call this inside region a wire throughout. Here we see that if we had translational invariance (parameters constant everywhere) we could Fourier transform to get a familiar looking Greenâ€™s function of \(G(k,\omega) = 1/(ak^2 +b\omega^2)\) for constants \(a,b\). Through complex analysis this can be transformed back, but we cannot rely on that method now.</p>

<h3 id="conditions-on-the-greens-function">Conditions on the Greenâ€™s Function</h3>

<p>Now we will look at what the properties the Greenâ€™s function has, by investigating the defining equation. Because it contains no derivatives of delta functions, we see that the Greenâ€™s function must be <em>continuous</em> everywhere as if it contains any discontinuities then taking the second spatial derivative of this will produce derivatives of the delta function. Therefore at all possible problem points (\(x=0,x=x',x=L\)) the Greenâ€™s function will be continuous. To see the effect of derivatives we integrate in a thin strip of size \(2\delta\) around a certain point \(y= \{ 0,x',L\}\),</p>

\[\begin{equation}
     \int_{y-\delta}^{y+\delta} dx \Bigg[ -\partial_x \frac{v}{K} \partial_x + \frac{\omega^2}{vK} \Bigg] G_{\omega'}(x,x') = \int_{y-\delta}^{y+\delta}  \delta(x-x')
\end{equation}\]

<p>We can see that the RHS of the equation will be zero unless \(y=x'\) and then it will equal 1 even as we let \(\delta \rightarrow0\). Turning our attention to the LHS, we see that the factor \((\omega^2/vK) G\) will give zero as we let \(\delta \rightarrow0\) due to the continuity of everything in the integrand. The terms with the spatial derivatives however will give a result of</p>

\[\begin{equation}
    \Big[ \frac{v(x)}{K(x)}\partial_x G(x,x') \Big]^{y+0}_{y-0} = \left\{
                \begin{array}{ll}
                  0 \quad \text{if } y=0,L\\
                  1 \quad \text{if } y=x'\\
                \end{array}
              \right.
\end{equation}\]

<p>These are all our conditions, so we should now look at what the solutions at various parts are.</p>

<h3 id="finding-our-pieces">Finding our pieces</h3>

<p>We can solve the problem away from the \(x=x'\) point, this can be seen to give an exponential dependence (with terms that diverge being set to zero).</p>

\[\begin{equation}
    G_0^L = Ae^{\omega x/v}, \quad G_W^L = Be^{\omega x/v} + Ce^{-\omega x/v}, \quad G_1^L = De^{-\omega x/v}
\end{equation}\]

<p>where \(G_0\) is the region to the left of the wire, \(G_W\) is in the wire and \(G_1\) is to the right of the wire. The \(L\) notation is to denote that these are left of the point \(x'\). To the right of this point we will have similar solutions with different coefficients which will be notated with primes. To simplify the more complicated problem, we will only consider that \(0&lt;x'&lt;L\) which will reduce the complication of stitching the solutions together. So we need to glue together \(G_0^L, G_W^L, G_W^R, G_1^R\) in accordance with the boundary conditions.</p>

<p>To summarise a bit, these boundary conditions mean that (as we have fixed \(x'\) to be within the wire) that we need to make the \(G_0^L, G_W^L\) boundary such that the function is continuous and to the same for \(G_W^R, G_1^R\). Then the gluing together of \(G^L\) and \(G^R\) parts is done by matching the Greenâ€™s function with a unit step in the derivative.</p>

<h3 id="gluing-together">Gluing together</h3>

<p>Up to now, I have repeatedly talked about gluing solutions together - but what is mathematically meant by this? Essentially we will use two step functions, \(\Theta(x)\), to ensure that the solutions are non-zero and zero respectively in the correct sections. So for the continuous boundary we will have,</p>

\[G^L(x&lt;x') = A G^L_0(x)\Theta(-x) + B G^L_W(x)\Theta(x)\]

<p>where we can see that action of the step functions kicking in at \(x=0\). Derivatives of this can now be taken, but any worrisome delta function terms that arise from differentiating the step function are killed off by one of the step functions having a negative sign and the continuity requirement meaning that \(A G^L_0(0) = BG^L_W(0)\). For the gluing over the continuous boundaries (\(x=0,L\)), we set the two parts of the functions and their derivatives to be equal at the boundary - much like in the standard QM problem except with the prefactor of the derivatives being different on either side. This allows us to relate the coefficients \(A\) and \(B\) to obtain an expression for \(G^L\) (with the final constant being set by larger considerations of the system, normalisation and whatnot).</p>

<p>The boundary with the derivative step can be solved for in the same way - writing out using theta functions and then relating the coefficients. This time however, the delta function in the derivative will not  So generically we solve for a solution where the coefficients can depend on where \(x'\) is set. This means \(G^L(x,x') = a(x')y_1(x)\) and \(G^R(x,x') = b(x')y_2(x)\) where \(y(x)\) contains the exponential \(x\) dependence of the Greenâ€™s function. Relating the two for \(x=x'\), using the conditions on our Greenâ€™s function.</p>

\[\begin{align}
    &amp;G^L(x=x',x') = G^R(x=x',x') = a(x') y_1(x=x') = b(x') y_2(x=x'), \\
    &amp; b y'_2 - a y'_1 = K(x=x')/v(x=x')
\end{align}\]

<p>This notation is very ugly but itâ€™s important to be clear on the dependence of various things. This can be solved for \(a,b\) (by just rearranging the above two equations) to give,</p>

\[\begin{equation}
  b = \frac{K}{v}\frac{y_1}{y_1y'_2 - y_2y'_1} \Big\vert_{x=x'}, \ \quad a = \frac{K}{v}\frac{y_2}{y_1y'_2 - y_2y'_1} \Big\vert_{x=x'}
\end{equation}\]

<p>which we can then use to get our full expression for the Greenâ€™s function which can be checked to satisfy our original differential equation.</p>

\[\begin{equation}
    G(x,x') = \frac{K}{v} \frac{1}{y_1 y'_2 - y_2y'_1}\Big\vert_{x=x'} \Big(\Theta(x'-x) y_1(x)y_2(x') + \Theta(x-x')y_2(x)y_1(x')\Big)
\end{equation}\]

<p>where the prefactor that is evaluated at \(x=x'\) is actually the inverse of the Wronskian of the two solutions evaluated at this point. I prefer to write it more explicitly. The generalisation to the \(y\) representation of the exponential dependence does make this particular question a little harder to follow (because of the multiple different exponential parts hidden within) but was used to show the more general technique.</p>

<p>The prefactor of the above equation actually turns out to be constant so we can evaluate its value anywhere! To show this we consider the derivative of the prefactor,</p>

<p>$$
\frac{d}{dx}\Big(\frac{v}{K}(y_1 yâ€™_2 - y_2yâ€™_1)\Big) = \frac{d}{dx}\Big(\frac{v}{K} \Big)(y_1 yâ€™_2 - y_2yâ€™_1) + \frac{v}{K}(yâ€™_1yâ€™_2 - yâ€™_2yâ€™_1 + y_1yâ€™â€˜_2 - y_2yâ€™â€˜_1)</p>

<p>This technique is quite general and can be shown to be equivalent to the eigenvalue method. This technique is standard in mathematical treatments of solving differential equations, but often in physics our laser focus on eigenvalues means that this method of constructing Greenâ€™s functions is overlooked!</p>

<p>So we have managed to stitch it all together and find our translationally variant Greenâ€™s function!</p>

<p>Thereâ€™s good info on this same process at the following link:</p>

<p><a href="http://www.damtp.cam.ac.uk/user/dbs26/1BMethods/GreensODE.pdf">http://www.damtp.cam.ac.uk/user/dbs26/1BMethods/GreensODE.pdf</a></p>
:ET