<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-01-25T11:29:05+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">More is Difficult</title><subtitle>Physics Notes</subtitle><author><name>Rose Davies</name><email>rxd440@student.bham.ac.uk</email></author><entry><title type="html">Solving without translational invariance - Operators</title><link href="http://localhost:4000/maths%20heavy/techniques/Operators/" rel="alternate" type="text/html" title="Solving without translational invariance - Operators" /><published>2021-01-07T00:00:00+00:00</published><updated>2021-01-07T00:00:00+00:00</updated><id>http://localhost:4000/maths%20heavy/techniques/Operators</id><content type="html" xml:base="http://localhost:4000/maths%20heavy/techniques/Operators/">&lt;p&gt;In the previous blog post, a way to stitch together Green’s functions to get an overall non-homogeneous result was explored. The thing that broke translational invariance in that case was a change in the parameters of the system between two different constant values. This is obviously not the only way in which we can break this symmetry.&lt;/p&gt;

&lt;p&gt;The way that will be looked into here is due to terms in the Hamiltonian of our system being local. The overall technique remains the same, solving either side and then gluing the pieces together. This time, however, instead of performing this to the Green’s function we will glue operators. There are many parallels between the two techniques though!&lt;/p&gt;

&lt;p&gt;In fact the technique that will be explored shares a lot of similarities with the simpler quantum mechanics problem of a particle with a potential barrier. Through application of the conditions of continuity of the wavefunction and its derivatives we can relate the coefficients of the wavefunction. The generalisation of this to a full field theory perspective is interesting as again it now requires us to deal with a situation without full translational symmetry - meaning the usual approach must be altered slightly.&lt;/p&gt;

&lt;p&gt;This example is taken from the notes on refermionisation in my Egger-Grabert 1998 paper, although Chamon, Freed, and Wen’s 1996 paper is a lot more clear.&lt;/p&gt;

&lt;h2 id=&quot;the-hamiltonian&quot;&gt;The Hamiltonian&lt;/h2&gt;

&lt;p&gt;So we introduce our Hamiltonian with no context&lt;/p&gt;

\[\begin{equation}
    H = \int dx \psi^{\dagger}\partial_x \psi + V(c + c^{\dagger})(\psi(0) + \psi^{\dagger}(0))
\end{equation}\]

&lt;p&gt;The kinetic term has that particular form as it is a sum over modes with a linear dispersion (thats been Fourier transformed back). There is an infinitely thin barrier at the origin that separates two regions in which the system is non-interacting. Interestingly because this comes from a refermionisation there is a Majorana mode from \(c + c^{\dagger}\) (which can be seen to be equal it Hermitian conjugate and therefore is its own antiparticle) meant to ensure that the combination in the Hamiltonian behaves in a fermionic manner. This is because \(\psi\) is actually the exponential of a bosonic field and can therefore cannot possess fermionic statistics.&lt;/p&gt;

&lt;p&gt;So after all these caveats about what the system is, we now just have a scattering problem which can be solved in a variety of ways. Here we will find the equations of motion for the system, where the majorana mode has been renamed \(f\)&lt;/p&gt;

\[\begin{equation}
    -i\partial_t \phi = [H, \phi] = i\partial_x \phi + Vf\delta(x), \quad \quad -i\partial_t \phi^{\dagger} = [H, \phi] = i\partial_x \phi^{\dagger} - Vf\delta(x),
\end{equation}\]

&lt;p&gt;and the time dependence of the Majorana mode must also be found and solved for,&lt;/p&gt;

\[\begin{equation}
    -i\partial_t f = [H,f] = V(\psi(0) - \psi^{\dagger}(0))
\end{equation}\]

&lt;h3 id=&quot;solving-the-individual-pieces&quot;&gt;Solving the individual pieces&lt;/h3&gt;

&lt;p&gt;Away from \(x=0\) the field can be found and solved for as it must satisfy the equation \((i\partial_t + i\partial_x)\psi = 0\), with the form of \(\psi\) being able to be found by taking the Fourier transform into frequency space.&lt;/p&gt;

\[\sum_{\omega} e^{i\omega t} (\omega + i\partial_x)A_{\omega}(x) = 0\]

&lt;p&gt;As this is true for all \(\omega\) we can see that \(-\omega A_{\omega}(x) = i\partial_xA_{\omega}(x)\). This can be solved to get \(A_{\omega}(x) = a_{\omega}e^{i\omega x}\).&lt;/p&gt;

&lt;p&gt;This must can be different either side of \(x=0\) so in general our solution will be,&lt;/p&gt;

\[\begin{equation}
    \psi(x,t) = \frac{1}{L}\sum_{\omega} e^{i\omega(t -x)} \left\{
                \begin{array}{ll}
                  a_{\omega}, \quad (x&amp;lt;0)\\
                  b_{\omega}, \quad (x&amp;gt;0)\\
                \end{array} = \frac{1}{L}\sum_k e^{i\omega(t -x)} \ ( \Theta(-x)a_{\omega} + \Theta(x)b_{\omega})
              \right.
\end{equation}\]

&lt;h3 id=&quot;joining-the-parts-together&quot;&gt;Joining the parts together&lt;/h3&gt;

&lt;p&gt;To find the boundary condition to join these two solutions together we must solve for \(f\) which involves defining \(\psi(0)\). This must contain parts from our operators either side of our discontinuity and to ensure that our definition of \(\psi(0)\) commutes with its Hermitian conjugate to give a delta function (not 4 times the delta function or whatever). We define \(\psi(0) = (\psi(0^+) + \psi(0^-))/2\), as \(\{a_{\omega},b^{\dagger}_{\omega}\}=1\) in addition to the more obvious commutation relations - hence the \(1/2\). Therefore solving for \(f\) with this definition we can find that,&lt;/p&gt;

\[\begin{equation}
    f_{\omega} = \frac{V}{2\omega}(\psi_{\omega}(0) - \psi_{\omega}^{\dagger}(0)) =  \frac{V}{2\omega}(a_{\omega} + b_{\omega} - a^{\dagger}_{-\omega} - b^{\dagger}_{-\omega})
\end{equation}\]

&lt;p&gt;The \(-\omega\) arises from making sure that the exponentials in our definition of the Fourier series are the same for the operator and its conjugate. Now we plug back into the equations of motion, splitting the full solution up into \(\psi_L(x,t) = \frac{1}{L} \sum_{\omega} e^{i\omega(t- x)} a_{\omega}\) and \(\psi_R\) respectively, joined together by a theta function. This gives,&lt;/p&gt;

\[\begin{equation}
    (i\partial_t + i\partial_x)(\psi_L\Theta(-x) + \psi_R\Theta(x)) = -Vf\delta(x)
\end{equation}\]

&lt;p&gt;Expanding out and differentiating the step functions gives&lt;/p&gt;

\[\begin{equation}
    \Theta(-x)(i\partial_t + i\partial_x)\psi_L + \Theta(x)(i\partial_t + i\partial_x)\psi_R + i\psi_L\partial_x\Theta(-x) + i\psi_R\partial_x\Theta(x) =  -Vf\delta(x)
\end{equation}\]

&lt;p&gt;From the defining differential equation for \(\psi\), we can see that the first two terms will be zero to give.&lt;/p&gt;

\[\begin{equation}
    i(\psi_R - \psi_L)\delta(x) = -2Vf(x)\delta(x)
\end{equation}\]

&lt;p&gt;therefore we can equate the two coefficients of the delta function. For the mathematicians, everything is secretly under an integral so this process actually makes sense. Finally we take the Fourier transform of our result to get a relation between \(a_{\omega}, b_{\omega}, a^{\dagger}_{\omega}, b^{\dagger}_{\omega}\),&lt;/p&gt;

\[\begin{equation}
    i(b_{\omega} - a_{\omega}) = -\frac{V^2}{2\omega}(a_{\omega} + b_{\omega} - a^{\dagger}_{-\omega} - b^{\dagger}_{-\omega})
\end{equation}\]

&lt;p&gt;and the procedure can be repeated on the equation of motion for the conjugate \(\psi^{\dagger}\).&lt;/p&gt;

\[\begin{equation}
    i(b^{\dagger}_{-\omega} - a^{-\dagger}_{\omega}) = \frac{V^2}{2\omega}(a_{\omega} + b_{\omega} - a^{\dagger}_{-\omega} - b^{-\dagger}_{\omega})
\end{equation}\]

&lt;p&gt;This gives two equations from which we can add to find an expression for \(b^{\dagger}_{\omega}\). Substituting in and performing the trick of adding and subtracting 1 in the from of \(i\omega +V^2/i\omega +V^2\) to obtain a relations between the scattering components,&lt;/p&gt;

\[\begin{equation}
    2b_{\omega} = ( 1 + \frac{i\omega- V^2}{i\omega + V^2})a_{\omega} + ( 1 - \frac{i\omega - V^2}{i\omega+ V^2})a^{-\dagger}_k
\end{equation}\]

&lt;h3 id=&quot;small-sprinkle-of-analysis&quot;&gt;Small sprinkle of analysis&lt;/h3&gt;

&lt;p&gt;So what we have done here is relate the operators either side of a barrier - the typical quantum mechanical problem in the field theoretic way. Solving this problem in QM (see this stack exchange - well up to a minus sign&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;) is a little easier and follows the previous blog post by requiring a discontinuity in the derivative. This problem just requires a little more care to derive.&lt;/p&gt;

&lt;p&gt;Just to close this out, I’ll mention some ways in which this relationship is useful and what it can tell us.&lt;/p&gt;

&lt;p&gt;As \(b_{\omega}\) creates a particle moving to the left from the right hand side, we can see that the difference between the coefficients of the operators on the left hand side of the discontinuity is the phase shift caused by scattering. A particle incident on the barrier will be reflected with a shift of its coefficient. We can summarise the shift as&lt;/p&gt;

\[e^{i\alpha_{\omega}} = e^{-i\alpha_{\omega}} = \frac{i\omega - V^2}{i\omega + V^2}\]

&lt;p&gt;This can be picked out from the form of our relation and this phase shift is the same as in the quantum mechanical problem. As another point of what we can do with this relation is that expectation values of \(\langle b^{\dagger}b \rangle\) can be evaluated in terms of the other operators (and vice versa) which allows us to solve some problems.&lt;/p&gt;

&lt;p&gt;So the one that appears in the Egger-Grabert notes (which this point is lifted from) has boundary conditions of our problem expressed in terms of \(\langle b^{\dagger}b \rangle, \langle a^{\dagger}a \rangle\). This relation is what allows us to relate the two to actually solve the effect of the boundaries on our system.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://physics.stackexchange.com/questions/441616/scattering-by-a-delta-function-well-in-1d&quot;&gt;https://physics.stackexchange.com/questions/441616/scattering-by-a-delta-function-well-in-1d&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Rose Davies</name><email>rxd440@student.bham.ac.uk</email></author><category term="Maths Heavy" /><category term="Techniques" /><category term="Boundary Conditions" /><category term="Operators" /><summary type="html">Dealing with localised terms in the Hamiltonian by stitching operators</summary></entry><entry><title type="html">Solving without translational invariance - Green’s functions</title><link href="http://localhost:4000/maths%20heavy/techniques/Stitching/" rel="alternate" type="text/html" title="Solving without translational invariance - Green’s functions" /><published>2021-01-05T00:00:00+00:00</published><updated>2021-01-05T00:00:00+00:00</updated><id>http://localhost:4000/maths%20heavy/techniques/Stitching</id><content type="html" xml:base="http://localhost:4000/maths%20heavy/techniques/Stitching/">&lt;p&gt;While I was attempting to rederive some results from a classic 1D transport paper, I got stuck trying to solve for the Green’s function of the system. The main problem wasn’t a horrendous integral or lack of convergence, but that in the system I was considering there was &lt;em&gt;no translational invariance&lt;/em&gt;. The whole usual method of Fourier transforming our Green’s function into a diagonal basis, inverting it and transforming back could not be used. Our lack of translational invariance means that the Fourier transform no longer neatly decouples our problem into a diagonal basis.&lt;/p&gt;

&lt;p&gt;To be clearer, the usual procedure is to start with our generic Green’s function, \(G(x,x')\), which if we have translational invariance will be a function of the difference of \(x\) and \(x'\) alone, \(G(x-x')\). This reduction of the number of parameters needed means that the Fourier transform only requires one \(k\) to get our answer, \(\tilde{G}(k)\), into a form that we can easily invert. Without translational invariance our Green’s function will depend on \(k\) and \(k'\) in general.&lt;/p&gt;

&lt;p&gt;It isn’t often that we lack translational invariance in physics due to the fact that it is what makes many calculations possible, however there is a neat way to solve the issue in certain cases (otherwise I wouldn’t be writing this at all!). Content here has been lifted from my research into Maslov and Stone’s 95 paper, full notes of which may appear at some point.&lt;/p&gt;

&lt;p&gt;This short explanation will focus on solving the issue when we are focused on finding the Green’s function to describe the system. Another entry will show a different way in which we can tackle another problem that directly deals with the operators themselves.&lt;/p&gt;

&lt;h2 id=&quot;greens-function-method&quot;&gt;Green’s Function method&lt;/h2&gt;

&lt;p&gt;So simply quoting what the mathematical problem is without much context&lt;/p&gt;

\[\begin{equation}
    \Bigg[-\partial_x \frac{v(x)}{K(x)} \partial_x + \frac{\omega^2}{v(x)K(x)} \Bigg] G_{\omega}(x,x') = \delta(x-x')
\end{equation}\]

&lt;p&gt;where the parameters \(v(x), K(x)\) are constant when \(x&amp;lt;0, x&amp;gt;L\) and have a different constant value when \(0 \le x \le L\). We will call this inside region a wire throughout. Here we see that if we had translational invariance (parameters constant everywhere) we could Fourier transform to get a familiar looking Green’s function of \(G(k,\omega) = 1/(ak^2 +b\omega^2)\) for constants \(a,b\). Through complex analysis this can be transformed back, but we cannot rely on that method now.&lt;/p&gt;

&lt;h3 id=&quot;conditions-on-the-greens-function&quot;&gt;Conditions on the Green’s Function&lt;/h3&gt;

&lt;p&gt;Now we will look at what the properties the Green’s function has, by investigating the defining equation. Because it contains no derivatives of delta functions, we see that the Green’s function must be &lt;em&gt;continuous&lt;/em&gt; everywhere as if it contains any discontinuities then taking the second spatial derivative of this will produce derivatives of the delta function. Therefore at all possible problem points (\(x=0,x=x',x=L\)) the Green’s function will be continuous. To see the effect of derivatives we integrate in a thin strip of size \(2\delta\) around a certain point \(y= \{ 0,x',L\}\),&lt;/p&gt;

\[\begin{equation}
     \int_{y-\delta}^{y+\delta} dx \Bigg[ -\partial_x \frac{v}{K} \partial_x + \frac{\omega^2}{vK} \Bigg] G_{\omega'}(x,x') = \int_{y-\delta}^{y+\delta}  \delta(x-x')
\end{equation}\]

&lt;p&gt;We can see that the RHS of the equation will be zero unless \(y=x'\) and then it will equal 1 even as we let \(\delta \rightarrow0\). Turning our attention to the LHS, we see that the factor \((\omega^2/vK) G\) will give zero as we let \(\delta \rightarrow0\) due to the continuity of everything in the integrand. The terms with the spatial derivatives however will give a result of&lt;/p&gt;

\[\begin{equation}
    \Big[ \frac{v(x)}{K(x)}\partial_x G(x,x') \Big]^{y+0}_{y-0} = \left\{
                \begin{array}{ll}
                  0 \quad \text{if } y=0,L\\
                  1 \quad \text{if } y=x'\\
                \end{array}
              \right.
\end{equation}\]

&lt;p&gt;These are all our conditions, so we should now look at what the solutions at various parts are.&lt;/p&gt;

&lt;h3 id=&quot;finding-our-pieces&quot;&gt;Finding our pieces&lt;/h3&gt;

&lt;p&gt;We can solve the problem away from the \(x=x'\) point, this can be seen to give an exponential dependence (with terms that diverge being set to zero).&lt;/p&gt;

\[\begin{equation}
    G_0^L = Ae^{\omega x/v}, \quad G_W^L = Be^{\omega x/v} + Ce^{-\omega x/v}, \quad G_1^L = De^{-\omega x/v}
\end{equation}\]

&lt;p&gt;where \(G_0\) is the region to the left of the wire, \(G_W\) is in the wire and \(G_1\) is to the right of the wire. The \(L\) notation is to denote that these are left of the point \(x'\). To the right of this point we will have similar solutions with different coefficients which will be notated with primes. To simplify the more complicated problem, we will only consider that \(0&amp;lt;x'&amp;lt;L\) which will reduce the complication of stitching the solutions together. So we need to glue together \(G_0^L, G_W^L, G_W^R, G_1^R\) in accordance with the boundary conditions.&lt;/p&gt;

&lt;p&gt;To summarise a bit, these boundary conditions mean that (as we have fixed \(x'\) to be within the wire) that we need to make the \(G_0^L, G_W^L\) boundary such that the function is continuous and to the same for \(G_W^R, G_1^R\). Then the gluing together of \(G^L\) and \(G^R\) parts is done by matching the Green’s function with a unit step in the derivative.&lt;/p&gt;

&lt;h3 id=&quot;gluing-together&quot;&gt;Gluing together&lt;/h3&gt;

&lt;p&gt;Up to now, I have repeatedly talked about gluing solutions together - but what is mathematically meant by this? Essentially we will use two step functions, \(\Theta(x)\), to ensure that the solutions are non-zero and zero respectively in the correct sections. So for the continuous boundary we will have,&lt;/p&gt;

\[G^L(x&amp;lt;x') = A G^L_0(x)\Theta(-x) + B G^L_W(x)\Theta(x)\]

&lt;p&gt;where we can see that action of the step functions kicking in at \(x=0\). Derivatives of this can now be taken, but any worrisome delta function terms that arise from differentiating the step function are killed off by one of the step functions having a negative sign and the continuity requirement meaning that \(A G^L_0(0) = BG^L_W(0)\). For the gluing over the continuous boundaries (\(x=0,L\)), we set the two parts of the functions and their derivatives to be equal at the boundary - much like in the standard QM problem except with the prefactor of the derivatives being different on either side. This allows us to relate the coefficients \(A\) and \(B\) to obtain an expression for \(G^L\) (with the final constant being set by larger considerations of the system, normalisation and whatnot).&lt;/p&gt;

&lt;p&gt;The boundary with the derivative step can be solved for in the same way - writing out using theta functions and then relating the coefficients. This time however, the delta function in the derivative will not  So generically we solve for a solution where the coefficients can depend on where \(x'\) is set. This means \(G^L(x,x') = a(x')y_1(x)\) and \(G^R(x,x') = b(x')y_2(x)\) where \(y(x)\) contains the exponential \(x\) dependence of the Green’s function. Relating the two for \(x=x'\), using the conditions on our Green’s function.&lt;/p&gt;

\[\begin{align}
    &amp;amp;G^L(x=x',x') = G^R(x=x',x') = a(x') y_1(x=x') = b(x') y_2(x=x'), \\
    &amp;amp; b y'_2 - a y'_1 = K(x=x')/v(x=x')
\end{align}\]

&lt;p&gt;This notation is very ugly but it’s important to be clear on the dependence of various things. This can be solved for \(a,b\) (by just rearranging the above two equations) to give,&lt;/p&gt;

\[\begin{equation}
  b = \frac{K}{v}\frac{y_1}{y_1y'_2 - y_2y'_1} \Big\vert_{x=x'}, \ \quad a = \frac{K}{v}\frac{y_2}{y_1y'_2 - y_2y'_1} \Big\vert_{x=x'}
\end{equation}\]

&lt;p&gt;which we can then use to get our full expression for the Green’s function which can be checked to satisfy our original differential equation.&lt;/p&gt;

\[\begin{equation}
    G(x,x') = \frac{K}{v} \frac{1}{y_1 y'_2 - y_2y'_1}\Big\vert_{x=x'} \Big(\Theta(x'-x) y_1(x)y_2(x') + \Theta(x-x')y_2(x)y_1(x')\Big)
\end{equation}\]

&lt;p&gt;where the prefactor that is evaluated at \(x=x'\) is actually the inverse of the Wronskian of the two solutions evaluated at this point. I prefer to write it more explicitly. The generalisation to the \(y\) representation of the exponential dependence does make this particular question a little harder to follow (because of the multiple different exponential parts hidden within) but was used to show the more general technique.&lt;/p&gt;

&lt;p&gt;The prefactor of the above equation actually turns out to be constant so we can evaluate its value anywhere! To show this we consider the derivative of the prefactor,&lt;/p&gt;

\[\frac{d}{dx}\Big(\frac{v}{K}(y_1 y'_2 - y_2y'_1)\Big) = \frac{d}{dx}\Big(\frac{v}{K} \Big)(y_1 y'_2 - y_2y'_1) + \frac{v}{K}(\underbrace{y'_1y'_2 - y'_2y'_1}_{0} + y_1y''_2 - y_2y''_1)\]

&lt;p&gt;and then consider our defining equation for what \(y_1\) and \(y_2\) must satisfy (ie the Green’s function differential equation away from the delta function spike)&lt;/p&gt;

\[\begin{equation}
    \frac{\omega^2}{v(x)K(x)}y = \partial_x \frac{v(x)}{K(x)} \partial_xy  = \frac{d}{dx}\Big(\frac{v}{K} \Big)y' + \frac{v(x)}{K(x)}y''
\end{equation}\]

&lt;p&gt;Therefore the spatial derivative of the prefactor can be seen to be&lt;/p&gt;

\[\text{Derivative of prefactor} = y_1\frac{\omega^2}{vK}y_2 - y_2\frac{\omega^2}{vK}y_1 = 0\]

&lt;p&gt;so the prefactor itself must be a constant as we vary space - so we have some translational invariance after all!&lt;/p&gt;

&lt;p&gt;This technique is quite general and can be shown to be equivalent to the eigenvalue method. This technique is standard in mathematical treatments of solving differential equations, but often in physics our laser focus on eigenvalues means that this method of constructing Green’s functions is overlooked!&lt;/p&gt;

&lt;p&gt;So we have managed to stitch it all together and find our translationally variant Green’s function!&lt;/p&gt;

&lt;p&gt;There’s good info on this same process at the following link:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.damtp.cam.ac.uk/user/dbs26/1BMethods/GreensODE.pdf&quot;&gt;http://www.damtp.cam.ac.uk/user/dbs26/1BMethods/GreensODE.pdf&lt;/a&gt;&lt;/p&gt;</content><author><name>Rose Davies</name><email>rxd440@student.bham.ac.uk</email></author><category term="[&quot;Maths Heavy&quot;, &quot;Techniques&quot;]" /><category term="Green's Functions" /><category term="Boundary Conditions" /><summary type="html">A method for stitching together a patchwork of Green's functions</summary></entry><entry><title type="html">Showing that solitons carry fractional charge</title><link href="http://localhost:4000/maths%20light/arguments/Soliton/" rel="alternate" type="text/html" title="Showing that solitons carry fractional charge" /><published>2020-12-02T00:00:00+00:00</published><updated>2020-12-02T00:00:00+00:00</updated><id>http://localhost:4000/maths%20light/arguments/Soliton</id><content type="html" xml:base="http://localhost:4000/maths%20light/arguments/Soliton/">&lt;p&gt;The concept of a soliton is often only introduced at a graduate level, due to the difficulty of the topics that it appears in. It is probably because of this difficulty that there are many interesting features of a soliton, which is why it’s a shame that it is left til so late to be introduced.&lt;/p&gt;

&lt;p&gt;The feature that will be looked at here is about the fractional charge that a soliton carries. Fractional charge means here that the ‘particle’ carries fractions of the bare electric charge \(e\), and this is in spite of an electron not being made up of more fundamental particles (at least it was the last time I checked what high energy physicists are doing). So what is happening here is a different from how a proton is made up of multiple quarks which have fractions of the electric charge \(e\) - this is why these objects are interesting!&lt;/p&gt;

&lt;p&gt;The proof of this normally involves quantum field theoretic techniques and was pioneered by Jackiw and Rebbi &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; and Su, Schrieffer, and Heeger&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. The latter group were attempting to describe a material, polyacetylene, and their model became known as the SSH model. It is SSH model that we are going to look at.&lt;/p&gt;

&lt;p&gt;The only knowledge needed here is some basic understanding of how chemical bonds work and belief that lowest energy ground state has the form that I will state, which is why this short proof is so unique!&lt;/p&gt;

&lt;h2 id=&quot;ssh-model&quot;&gt;SSH Model&lt;/h2&gt;

&lt;p&gt;In physics it is often our task to find the lowest energy state of the system as this is what our system would like to be doing. The SSH model is defined on a linear chain of atoms with chemical bonds being between each site. The lowest energy state turns out to be an alternating pattern of single and double bonds (corresponding to one or two electrons being shared between the atoms&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;) as drawn below for a section of the chain.&lt;/p&gt;

&lt;figure class=&quot;align-center&quot;&gt;
&lt;img src=&quot;../../../images/posts/SSh-A.jpg&quot; style=&quot;width: 70%&quot; class=&quot;align-center&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;There however is a degeneracy and another possible arrangement of chemical bonds has the exact same energy as the previous state. The degeneracy is whether the alternating single and double bonds starts with a double or single bond&lt;/p&gt;

&lt;figure class=&quot;align-center&quot;&gt;
&lt;img src=&quot;../../../images/posts/SSh-B.jpg&quot; style=&quot;width: 70%&quot; class=&quot;align-center&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;We will label these two different configurations as \(A\) and \(B\)&lt;/p&gt;

&lt;h3 id=&quot;adding-kinks&quot;&gt;Adding Kinks&lt;/h3&gt;

&lt;p&gt;So having found the lowest energy state of the system, we now ask what happens if we mess with them and introduce differences in the pattern of single and double bonds. One of the most simple differences we can imagine is to have two double bonds next to each other and then have the system alternate as normal. This state is perfectly plausible but just may not be the lowest energy state of our system.&lt;/p&gt;

&lt;p&gt;These ‘differences’ are called kinks and correspond to our soliton. There are two ways of adding these in as either an extra double bond which here has been placed between sites 3-4&lt;/p&gt;

&lt;figure class=&quot;align-center&quot;&gt;
&lt;img src=&quot;../../../images/posts/SSh-kink.jpg&quot; style=&quot;width: 70%&quot; class=&quot;align-center&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;or we can introduce an extra single bond in a similar manner - these are the first two types of soliton. The are however kinks also anti-kinks and these depend on which configuration is either side of the defect (or difference). In the above example we have \(A\) on the left and \(B\) on the right, which we will call a kink. The opposite case of \(B\) on the left and \(A\) on the right is called an anti kink.&lt;/p&gt;

&lt;p&gt;So we can see that this kink separates a region of the \(A\) configuration and begins the onset of the \(B\) configuration. In 1D these are what solitons are - they are barriers that separate two different regions. Often these are called domain walls (there a lot of terminology for essentially the same thing here). A more familiar example is in magnets where the direction of magnetisation can point in different directions and the way to describe how the regions of different magnetisation move around is through solitons!&lt;/p&gt;

&lt;p&gt;A point to note is that these solitons are topological. To figure out why, we need to know that electrons and bonds can hop around - what quantum mechanics says is that there will always be fluctuations around the ground state. There is no way to however try to rearrange the bonds through swapping them that will change our chain with a kink in into a chain of configuration \(A\) (or configuration \(B\)) only. Although you could swap configuration \(A\) to have two double bonds next to each other (ie swapping 4-5 and 3-4) there would be three single bonds next to each other which isnt the same as the kink state.&lt;/p&gt;

&lt;p&gt;This is what is meant by topological, that there is no way that the system, when left to its own devices (ie swapping bonds), can get rid of a kink without an external input (ie removing the bond entirely).&lt;/p&gt;

&lt;h3 id=&quot;normal-is-having-2-kinks&quot;&gt;Normal Is Having 2 Kinks&lt;/h3&gt;

&lt;p&gt;Having gone through adding one of these solitons, let us now add two double bond defects. From the description of a kink and antikink having different configurations either side of them, adding a kink and an anti-kink must be the only way to have two of these defects in our system&lt;/p&gt;

&lt;figure class=&quot;align-center&quot;&gt;
&lt;img src=&quot;../../../images/posts/SSh-2kink.jpg&quot; style=&quot;width: 70%&quot; class=&quot;align-center&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;Now for no apparently reason, let us consider what adding one normal electron to configuration \(B\) would look like, and we will specifically add it at sites 2-3,&lt;/p&gt;

&lt;figure class=&quot;align-center&quot;&gt;
&lt;img src=&quot;../../../images/posts/SSh-1elec.jpg&quot; style=&quot;width: 70%&quot; class=&quot;align-center&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;Comparing the two, in a coincidence noone could have seen coming, they turn out to be identical if we swapped bonds 3-4 and 4-5 (which is an allowed action). Therefore in some way the two kink state is equivalent to adding one electron to the ground state. This means that each kink must carry half the charge of an electron!&lt;/p&gt;

&lt;p&gt;Supporting this final step is that we can move each of these kinks arbitrarily far apart by swapping bonds but the system in total will always only have an extra charge of 1. If the 2 solitons were not in the system the there would be one less electron charge and therefore each soliton must be carrying half of the charge.&lt;/p&gt;

&lt;h3 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h3&gt;

&lt;p&gt;So this short little demonstration managed to show that a soliton (as we have defined here as a domain wall between different configurations) carries fractional charge which is quite a deep result. If we changed the ground state on the geometry to be a pattern of bonds that repeated every 3 sites (single-single-double) then the same argument can be applied to show that ‘solitons’ here carry a third of an electron charge.&lt;/p&gt;

&lt;p&gt;The solitons in the latter case will correspond to a different model (as SSH doesnt have that ground state!) but a model could be described which contains this triple repeating structure. This can be generalised more to get \(1/n\) of an electron charge for the solitons of various models.&lt;/p&gt;

&lt;p&gt;If you’re feeling brave, my notes on solitons are on this site and will explain in a field theoretic way the other strange properties that these excitations have.&lt;/p&gt;

&lt;p style=&quot;text-align: center&quot;&gt;&lt;a class=&quot;btn btn--Solitons btn--large&quot; style=&quot;text-align: center&quot; href=&quot;/Solitons/&quot;&gt;Go to Soliton notes&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;R. Jackiw and C. Rebbi, Phys. Rev. D 13, 3398 (1976). &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;W. P. Su, J. R. Schrieffer, and A. J. Heeger, Phys. Rev. Lett. 42, 1698 (1979), and Phys. Rev. B 22, 2099 (1980) &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;There is a subtlty about this as single and double bonds involve two and four electrons respectively, but it is that one of the electrons involved in the bond is bound tightly to the atom/sites and cannot move or hop. The other electron involve can move freely and swap with electrons involved in other bonds and as what we are describing in SSH is conduction electrons these are the only ones we actually care about. This requires a bit more knowledge on how physical chemistry works so I haven’t talked about it in detail - just to point out that there is no contradiction here! &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Rose Davies</name><email>rxd440@student.bham.ac.uk</email></author><category term="Maths Light" /><category term="Arguments" /><category term="Fractional Charge" /><category term="Solitons" /><summary type="html">A short, intuitive reason can be given to understand why the charge of solitons fractionalise.</summary></entry></feed>